# 百面机器学习-笔记

## 特征工程

- 为什么需要对数值类型的特征做归一化？
- 怎样处理类别型特征？
- 什么是组合特征？如何处理高维组合特征？
- 怎样有效地找到组合特征？
- 有哪些文本表示模型？它们各有什么优缺点？
- 如何缓解图像分类中训练数据不足带来的问题？
- Word2Vec是如何工作的？它和隐狄利克雷模型有什么区别与联系？

## 模型评估

- 准确率的局限性
- 精确率与召回率的权衡
- 平方根误差的“意外”
- 什么是ROC曲线？
- 为什么要进行在线A/B测试
- 过拟合和欠拟合具体是指什么现象？
- 如何绘制ROC曲线？
- 如何计算AUC？
- 为什么在一些场景中要使用余弦相似度而不是欧氏距离？
- 如何划分实验组和对照组？
- 模型评估过程中的验证方法及其优缺点
- 能否说出几种降低过拟合和欠拟合风险的方法？
- ROC曲线相比P-R曲线有什么特点？
- 余弦距离是否是一个严格定义的距离？
- 自助法采样在极限情况下会有多少数据从未被选择过？
- 超参数有哪些调优方法？

## 经典算法

- 逻辑回归相比线性回归，有何异同？
- 决策树有哪些常用的启发函数？
- 线性可分的两类点在SVM分类超平面上的投影仍然线性可分吗？
- 证明存在一组参数使得高斯核SVM的训练误差为0。
- 加入松弛变量的SVM的训练误差可以为0吗？
- 用逻辑回归处理多标签分类任务的一些相关问题。
- 如何对决策树进行剪枝？
- 训练误差为0的SVM分类器一定存在吗？

## 降维

- 从最大方差的角度定义PCA的目标函数并给出求解方法。
- 从回归的角度定义PCA的目标函数并给出对应的求解方法。
- 线性判别分析的目标函数以及求解方法。
- 线性判别分析与主成分分析的区别与联系

## 非监督学习

- K均值聚类算法的步骤是什么？
- 高斯混合模型的核心思想是什么？它是如何迭代计算的？
- K均值聚类的优缺点是什么？如何对其进行调优？
- 针对K均值聚类的缺点，有哪些改进的模型？
- 自组织映射神经网络是如何工作的？它与K均值算法有何区别？
- 怎样设计自组织映射神经网络并设定网络训练参数？
- 以聚类算法为例，如何区分两个非监督学习算法的优劣？
- 证明K均值聚类的收敛性。

## 概率图模型

- 解释朴素贝叶斯模型的原理，并给出概率图模型表示。
- 解释最大熵模型的原理，并给出概率图表示。
- 常见的主题模型有哪些？试介绍其原理。
- 如何确定LDA模型中的主题个数？
- 常见的概率图模型中，哪些是生成式，哪些是判别式的？
- 如何对中文分词问题用隐马尔科夫模型进行建模和训练？
- 如何用主题模型解决推荐系统中的冷启动问题？
- 最大熵马尔科夫模型为什么会产生标注偏置问题？如何解决？

## 优化算法

- 有监督学习涉及的损失函数有哪些？
- 训练数据特别大时经典梯度算法存在的问题，如何改进？
- 机器学习中哪些是凸优化问题？哪些是非凸优化问题？
- 无约束优化问题的求解。
- 随机梯度下降法失效的原因、
- 如何验证求目标函数梯度功能的正确性？
- 随机梯度下降法的一些变种。
- L1正则化使得模型参数具有稀疏性的原理是什么？

## 采样

- 如何编程实现均匀分布随机数生成器？
- 简述MCMC采样法的主要思想。
- 举例说明采样在机器学习中的应用。
- 简单介绍几种常见的MCMC采样法。
- MCMC采样法如何得到相互独立的样本？
- 简述一些常见的采样方法的主要思想和具体操作。
- 如何对高斯分布进行采样？
- 如何对贝叶斯网络进行采样？
- 当训练集中正负样本不均衡时，如何处理数据以更好地训练分类模型？

## 前向神经网络

- 写出常用激活函数及其导数。
- 神经网络训练时是否可以将参数全部初始化为0？
- 多层感知机表示异或逻辑时最少需要几个隐藏层？
- 为什么Sigmoid和Tanh激活函数会使梯度消失？
- 写出多层感知机的平方误差和交叉熵损失函数。
- 解释卷积操作中的稀疏交互和参数共享及其作用。
- 一个隐藏层需要多少隐节点能够实现包含n元输入的任意布尔函数？
- 多个隐层实现包含n元输入的任意布尔函数最少需要多少个节点和网络层？
- ReLU系列的激活函数的优点是什么？他们有什么局限性以及如何改进？
- 平方误差损失函数和交叉损失函数分别适合什么场景？
- 为什么Dropout可以抑制过拟合？简述它的工作原理和实现。
- 批量归一化的基本动机与原理是什么？在卷积神经网络中如何使用？
- 常见的池化操作有哪些？池化的作用是什么？
- 卷积神经网络如何用于文本分类任务？
- ResNet的提出背景和核心理论是什么？
- 根据损失函数推导各层参数更新的梯度计算公式。

## 循环神经网络

- 循环神经网络与前馈神经网络相比有什么特点？
- 循环神经网络为什么会出现梯度消失或梯度爆炸？有哪些改进方案？
- LSTM是如何实现长短期记忆功能的？
- 什么是Seq2Seq模型？它有哪些优点？
- 在循环神经网络中能否使用ReLU作为激活函数？
- LSTM里各模块分别使用什么激活函数？可以用其他的激活函数吗？
- Seq2Seq模型在解码时有哪些常用的方法？
- Seq2Seq模型引入注意力机制是为了解决什么问题？为什么选用双向循环神经模型？
- 在图像分类任务中怎么使用注意力机制？

## 强化学习

- 强化学习中有哪些基本概念？
- 什么是深度强化学习？它与传统的强化学习有什么不同？
- 在智能体与环境交互中，什么是探索和利用？如何平衡探索与利用？
- 什么是策略梯度下降？与传统Q-learning有什么不同？有什么优势？

## 集成学习

- 集成学习分为哪几种？它们有何异同？
- 常用的基分类器是什么？
- 集成学习有哪些基本步骤？请举几个集成学习的例子。
- 可否将随机森林中的基分类器由决策树替换为线性分类器或K-近邻？
- 什么是偏差和方差？
- GBOT的基本原理是什么？
- 梯度提升和梯度下降的区别和联系是什么？
- GBOT的优点和局限性有哪些？
- 如何从减小方差和偏差的角度解释Boosting和Bagging的原理？
- XGBoost与GBOT的联系和区别有哪些？

## 生成对抗网络

- 简述GAN的基本思想和训练过程。
- GANs如何避开大量概率推断计算？
- 如何构建一个生成器，生成一串文字组成的序列代表一个句子？
- GANs的值函数。
- 原GANs中存在哪些问题会成为制约模型训练效果的瓶颈？
- 在生成器和判别器中应该怎样设计深层卷积结构？
- 如何把一个生成网络和一个推断网络融合在GANs框架下？
- GANs最小化目标函数过程中会遇到什么问题？
- WGAN针对前面问题做了哪些改进？什么是Wasserstein距离？
- 怎样具体应用Wasserstein距离实现WGAN算法？
- 设计一种制造负样本的生成器来采样一些迷惑性强的负样本。
- 训练一个序列生成器的优化目标通畅是什么？GANs框架下这个优化目标有何不同？
- 有了GANs下生成器的优化目标，怎样求解目标函数对生成器参数的梯度？
